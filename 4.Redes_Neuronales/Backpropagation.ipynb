{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ovxm6yeglABg"
      },
      "source": [
        "# ¿CÓMO FUNCIONA EL ALGORITMO DE BACKPROPAGATION?\n",
        "\n",
        "Paso a paso de cómo funciona el algoritmo de retropropagación hacia atrás, que es una pieza fundamental de las Redes Neuronales Artificiales y muchas veces es considerado un \"misterio\".\n",
        "\n",
        "Está desarrollado en \"seudo código\", es decir, se explica como si estuvieramos con \"papel y lápiz\" desarrollando los cálculos. En un próximo blog discutiremos cómo implementarlo en Python usando Numpy.\n",
        "\n",
        "De manera fundamental, el algoritmo actualizará los parámetros de la red retropropagando el error hacia las capas interiores de la misma. Este proceso se realiza \"de derecha a izquierda\", es decir, se parte primero estimando el efecto que los parámetros de las capas más cerca de la salida tienen en el output de la red, y con esa información se comienza a estimar progresivamente el efecto de los parámetros de las capas ocultas hasta llegar a las capas de entrada.\n",
        "\n",
        "Para poder entender su funcionamiento, se recomienda tener conocimientos básicos de cálculo diferencial, esencialmente, de la regla de la cadena.\n",
        "\n",
        "A continuación, discutimos en detalle este algoritmo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhf3Sl7N-eYX"
      },
      "source": [
        "## 1. Definiendo la Arquitectura de la Red,\n",
        "### Supongamos una red simple con dos inputs i1 e i2, con una capa oculta con dos neuronas h1 y h2, y dos neuronas en la capa de salida o1 y o2:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPssTFmHNSHx"
      },
      "source": [
        "![texto alternativo](https://matthewmazur.files.wordpress.com/2018/03/neural_network-7.png) Figura 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtbshyH6-vDu"
      },
      "source": [
        "### En esta red, tanto las neuronas de la capa oculta, h1 y h2, y las de la capa de salida, o1 y o2 están siendo \"activadas\" ocupando la función logística (también conocida como sigmoide):\n",
        "\n",
        "![texto alternativo](https://s0.wp.com/latex.php?latex=out_%7Bo1%7D+%3D+%5Cfrac%7B1%7D%7B1%2Be%5E%7B-net_%7Bo1%7D%7D%7D&bg=ffffff&fg=404040&s=0&zoom=2)\n",
        "Ecuacion (1)\n",
        "\n",
        "\n",
        "### Supongamos ahora que queremos entrenar nuestra red con los siguientes valores:\n",
        "\n",
        "###cuando el input es i1= 0.05 queremos que nuestra salida sea o1=0.01 y\n",
        "###cuando el input es i2= 0.1 queremos que nuestra salida sea o2=0.99\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42yz6_CJ_wm-"
      },
      "source": [
        "### En nuestra primera iteración inicializaremos los parámetros de la red aleatoriamente. Supongamos que obtenemos los siguientes valores para nuestros coeficientes w y b:\n",
        "\n",
        "b1=0.35\n",
        "b2=0.6\n",
        "\n",
        "w1=0.15\n",
        "w2=0.2\n",
        "w3=0.25\n",
        "w4=0.3\n",
        "w5=0.4\n",
        "w6=0.45\n",
        "w7=0.5\n",
        "w8=0.55\n",
        "\n",
        "visualmente:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRvdiwiFNpoj"
      },
      "source": [
        "![texto alternativo](https://matthewmazur.files.wordpress.com/2018/03/neural_network-9.png) Figura 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dPyRLYGNLsm"
      },
      "source": [
        "#podemos escribir esto en código de python\n",
        "\n",
        "\n",
        "# los inputs estan dados\n",
        "i1=0.05\n",
        "i2=0.1\n",
        "\n",
        "# los outputs estan dados\n",
        "o1=0.01\n",
        "o2=0.99\n",
        "\n",
        "# iniciamos los parámetros w y b aleatoriamente y obtenemos estos resultados:\n",
        "b1=0.35\n",
        "b2=0.6\n",
        "\n",
        "w1=0.15\n",
        "w2=0.2\n",
        "w3=0.25\n",
        "w4=0.3\n",
        "w5=0.4\n",
        "w6=0.45\n",
        "w7=0.5\n",
        "w8=0.55\n",
        "\n",
        "# por supuesto en un código real tendriamos que inicializar los parámetros con algúna función aleatoria, por ejemplo, w_i=numpy.random.randn() o similar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsEG-raypnK8"
      },
      "source": [
        "## 2. FORWARD PASS\n",
        "#### Como ya contamos con los pesos aleatorios iniciales, podemos hacer los cálculos correspondientes. Esto se conoce como \"forward pass\", o \"feed forward\" porque haremos entrar los inputs a la red, \"de izquierda hacia la derecha\", realizando todos los cálculos hasta obtener nuestra primera estimación de las salidas de la red o1 y o2:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrDRdkfpOk2m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12e78e35-6e12-4da6-e38b-3e34ea8e017f"
      },
      "source": [
        "# Propagando los datos hacia adelante ->\n",
        "\n",
        "# Calculamos los valores netos de la neuronas de la capa oculta (netos, es decir, antes de aplicarles la función de activación logística)\n",
        "# podemos ver que es solo una suma ponderada de los inputs a los que se les suma un término constante o \"bias\":\n",
        "\n",
        "net_h1=i1*w1+i2*w2+b1\n",
        "net_h2=i1*w3+i2*w4+b1\n",
        "\n",
        "print('net_h1='+ str(net_h1))\n",
        "print('net_h2='+str(net_h2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "net_h1=0.3775\n",
            "net_h2=0.39249999999999996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvnb9kXoPF2K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a22288c-69ad-4fc7-89cc-de69a229dbfb"
      },
      "source": [
        "# Para calcular los valores finales o \"output\" de la neuronas, necesitamos aplicar la función de activación logística (u otra).\n",
        "\n",
        "# primero la definimos ocupando la Ecuación 1:\n",
        "import numpy as np\n",
        "def logistic_func(net):\n",
        "  out=1/(1+np.exp(-net))\n",
        "  return out\n",
        "\n",
        "# ahora la aplico a cada una de las neuronas de la capa oculta\n",
        "\n",
        "out_h1=logistic_func(net_h1)\n",
        "out_h2=logistic_func(net_h2)\n",
        "\n",
        "print('out_h1='+ str(out_h1))\n",
        "print('out_h2='+ str(out_h2))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out_h1=0.5932699921071872\n",
            "out_h2=0.596884378259767\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUo7uEa9C8eb"
      },
      "source": [
        "### Dado que ya hemos calculado los valores de la capa oculta, podemos proceder a calcular los valores de las neuronas de la capa de salida:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KgX4CMfQwV2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f63d55d-cb79-4416-c96b-c737723ff183"
      },
      "source": [
        "# primero calculamos el valor neto ocupando los pesos respectivos. notar que el input de las neuronas de la capa de salida o1 y o2,\n",
        "#es el output de las neuronas de la capa oculta\n",
        "\n",
        "net_o1=out_h1*w5+out_h2*w6+b2\n",
        "net_o2=out_h1*w7+out_h2*w8+b2\n",
        "\n",
        "print('net_o1='+ str(net_o1))\n",
        "print('net_o2='+ str(net_o2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "net_o1=1.10590596705977\n",
            "net_o2=1.2249214040964653\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz02uhaKDSaq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aa7e4f0-de7f-402f-e5c9-e2e68b94fd86"
      },
      "source": [
        "# nuevamente, a estos valores netos le aplicamos la función de activación Ecuación 1.\n",
        "out_o1=logistic_func(net_o1)\n",
        "out_o2=logistic_func(net_o2)\n",
        "\n",
        "print('out_o1='+ str(out_o1))\n",
        "print('out_o2='+ str(out_o2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out_o1=0.7513650695523157\n",
            "out_o2=0.7729284653214625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv9b-R4VDfPW"
      },
      "source": [
        "### Ya contamos con nuestra primera estimación para o1 y o2. Podemos comparar estos valores con respecto a los valores que deseamos la red aprenda a replicar i1 y i2. La diferencia entre ellos es el \"error\" de nuestra red:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8EQN5pRDetg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5982daa7-c332-45cf-84a4-209fd835e7c9"
      },
      "source": [
        "# Calculamos los errores\n",
        "\n",
        "e1=out_o1-o1\n",
        "e2=out_o2-o2\n",
        "\n",
        "print(e1,e2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7413650695523157 -0.21707153467853746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O2KyYrCEnGA"
      },
      "source": [
        "###Podemos observar que los valores predichos out_o1 y out_o2 están lejos de los valores buscados o1 y o2, por lo tanto, los errores son bastante grandes. Esto se debe a que los parámetros w y b que escogimos obviamente todavía no han sido optimizados.\n",
        "### Para medir qué tan lejos estamos de los valores deseados, ocupamos una métrica o medida de ajuste, también conocida como función de costo o función de pérdida (en inglés Cost function o Loss Function).\n",
        "### Existen muchas, pero en este ejemplo implementaremos una de las más utilizadas: el Error Cuadrático o Squared Error.\n",
        "### Se calcula simplemente como la diferencia al cuadrado, a veces multiplicada por una constante, en este caso 1/2, para facilitar algunas derivadas que ocuparemos más adelante en el proceso de optimización.\n",
        "\n",
        "![texto alternativo](https://s0.wp.com/latex.php?latex=E_%7Btotal%7D+%3D+%5Csum+%5Cfrac%7B1%7D%7B2%7D%28target+-+output%29%5E%7B2%7D&bg=ffffff&fg=404040&s=0&zoom=2)\n",
        " Ecuación 2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADu3KeAtFvrU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ceede15-8a08-4d79-d71d-6f31ffceea01"
      },
      "source": [
        "loss_e1=0.5*(e1**2)\n",
        "loss_e2=0.5*(e2**2)\n",
        "\n",
        "print(loss_e1,loss_e2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.274811083176155 0.023560025583847746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKAMB8V7Fyp7"
      },
      "source": [
        "### luego el error total de la red será simplemente la suma total de los errores al cuadrado cometidos en cada predicción.\n",
        "![texto alternativo](https://s0.wp.com/latex.php?latex=E_%7Btotal%7D+%3D+E_%7Bo1%7D+%2B+E_%7Bo2%7D+%3D+0.274811083+%2B+0.023560026+%3D+0.298371109&bg=ffffff&fg=404040&s=0&zoom=2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38wuhSKrVFZs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9afc0220-175f-43d6-9889-6e77ac5c953f"
      },
      "source": [
        "total_error=loss_e1+loss_e2\n",
        "print(total_error)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2983711087600027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvNSMg06WXPL"
      },
      "source": [
        "##3. BACKWARD PASS. Optimizando los parámetros w y b de la red\n",
        "\n",
        "### Sabemos que los parámetros w y b escogidos inicialmente no son óptimos, por lo que ahora queremos optimizarlos.\n",
        "### Para ello ocuparemos la técnica de gradiente descendiente. La idea es intentar estimar el efecto que cada uno de los parámetros de la red tiene sobre el error total de la misma. Si conocemos, por ejemplo, que incrementar el valor de w5 reducirá el error total, entonces, en la próxima iteración querremos ocupar un valor w5_actualizado>w5_anterior.\n",
        "\n",
        "### Dado que la red tiene muchas capas y muchas neuronas en cada capa, el procedimiento a seguir consiste en ir preguntándonos cómo afecta cada uno de los parámetros de manera \"encadenada\", es decir, iremos recorriendo la red desde la salida hacia la entrada, o, de derecha hacia la izquierda, e iremos viendo el efecto conjunto de cada sub-parte.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZc4_Xg7H-mj"
      },
      "source": [
        "## 3.1 Efecto de los parámetros de la capa de salida en el Error Total\n",
        "\n",
        "### Primero entonces, estimaremos el efecto de los parámetros w5, w6, w7, w8 en las neuronas de la capa de salida de la red, o1 y o2, y por consecuente, en los errores respectivos e1 y e2, y así en el error total.\n",
        "\n",
        "### Por ejemplo, ¿comencemos preguntándonos cúanto cambia el error total cuando cambia el parámetro w5?\n",
        "\n",
        "### Para contestar esta pregunta observe la Figura 3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gegaOvQDV0-C"
      },
      "source": [
        "![texto alternativo](https://matthewmazur.files.wordpress.com/2018/03/output_1_backprop-4.png) Figura 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1ySRkTVJYNI"
      },
      "source": [
        "### Vemos que se produce una \"cadena\", dado que el error total depende del valor Eo1 y Eo2, y estos del output de las neuronas o1 y o2.\n",
        "### A su vez, el valor ouput de o1, depende del valor neto de o1 y este finalmente de w5 y del valor de salida output de h1.  \n",
        "### Como el E_o2, no depende de w5 ni directa, ni indirectamente lo podemos omitir.\n",
        "\n",
        "### Podemos expresar esta relación matemáticamente como una derivada parcial:\n",
        "\n",
        "![texto alternativo](https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpartial+E_%7Btotal%7D%7D%7B%5Cpartial+w_%7B5%7D%7D+%3D+%5Cfrac%7B%5Cpartial+E_%7Btotal%7D%7D%7B%5Cpartial+out_%7Bo1%7D%7D+%2A+%5Cfrac%7B%5Cpartial+out_%7Bo1%7D%7D%7B%5Cpartial+net_%7Bo1%7D%7D+%2A+%5Cfrac%7B%5Cpartial+net_%7Bo1%7D%7D%7B%5Cpartial+w_%7B5%7D%7D&bg=ffffff&fg=404040&s=2&zoom=2) Ecuación 3\n",
        "\n",
        "### Note que la derivada de la Ecuación 3 sólo nos muestra cómo el resultado de la red se ve afectado por un sólo parámetro (w5) de la capa oculta. Dado que la red contiene muchos parámetros, al conjunto de derivadas que representan cómo se afectan cada uno de los w y b se conoce como \"Gradiente\".\n",
        "\n",
        "### Note además que el efecto de w5 en el error total (Ecuación 3), puede ser descompuesto en los componentes de la \"cadena\" mencionada cuando discutimos la Figura 3. Veamos ahora como podemos estimar cada uno de los estos componentes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsHXmMhNY6uU"
      },
      "source": [
        "### 3.1.1 Componente 1: cómo cambia el error total cuando cambia el out o1\n",
        "\n",
        "### Para estimar este efecto, necesitamos derivar el error total definido en la Ecuación 2, con respecto al output de la neurona o1. Derivando obtenemos:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oocCnZ66XD4X"
      },
      "source": [
        "![texto alternativo](https://s0.wp.com/latex.php?latex=E_%7Btotal%7D+%3D+%5Cfrac%7B1%7D%7B2%7D%28target_%7Bo1%7D+-+out_%7Bo1%7D%29%5E%7B2%7D+%2B+%5Cfrac%7B1%7D%7B2%7D%28target_%7Bo2%7D+-+out_%7Bo2%7D%29%5E%7B2%7D&bg=ffffff&fg=404040&s=0&zoom=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkWTYgpFXG8v"
      },
      "source": [
        "![texto alternativo](https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpartial+E_%7Btotal%7D%7D%7B%5Cpartial+out_%7Bo1%7D%7D+%3D+2+%2A+%5Cfrac%7B1%7D%7B2%7D%28target_%7Bo1%7D+-+out_%7Bo1%7D%29%5E%7B2+-+1%7D+%2A+-1+%2B+0&bg=ffffff&fg=404040&s=0&zoom=2) Ecuación 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtQ5JLPaNdNd"
      },
      "source": [
        "### Dado que conocemos el valor de o1 (target) y el valor de salida estimado por la red (out_o1) podemos calcular este efecto:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k43AD5AmXLvy"
      },
      "source": [
        "![texto alternativo](https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpartial+E_%7Btotal%7D%7D%7B%5Cpartial+out_%7Bo1%7D%7D+%3D+-%28target_%7Bo1%7D+-+out_%7Bo1%7D%29+%3D+-%280.01+-+0.75136507%29+%3D+0.74136507&bg=ffffff&fg=404040&s=0&zoom=2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa6Dr5-SWWuj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcb1c93e-4ff7-4885-8eb8-77a54e2121ec"
      },
      "source": [
        "# numéricamente:\n",
        "\n",
        "delta_e_wr_delta_out_o1=-(o1-out_o1)\n",
        "print(delta_e_wr_delta_out_o1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7413650695523157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mv0WbVKQYK95"
      },
      "source": [
        "### notar que el resultado es simplemente el Error 01!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tx5hqZIYdEy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9042b67b-7574-4c33-8a5b-bb49796008df"
      },
      "source": [
        "print(e1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7413650695523157\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3iqDQVzaP8l"
      },
      "source": [
        "### 3.1.2 Componente 2: ¿Cómo cambia el output de la neurona de salida 1 con respecto al valor de su input?\n",
        "### es equivalente a encontrar la derivada de la función de activación, en este caso logística, con respecto a su input. Recordando la Ecuación 1:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpJYM2MwZUHc"
      },
      "source": [
        "![texto alternativo](https://s0.wp.com/latex.php?latex=out_%7Bo1%7D+%3D+%5Cfrac%7B1%7D%7B1%2Be%5E%7B-net_%7Bo1%7D%7D%7D&bg=ffffff&fg=404040&s=0&zoom=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QRCo8j0YFCA"
      },
      "source": [
        "![texto alternativo](https://wikimedia.org/api/rest_v1/media/math/render/svg/1bb35c81bc043a65aef427a578c207f847472547) función logística o sigmoide"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km9xqgRqO2oF"
      },
      "source": [
        "### Su derivada respecto a su input es:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "381KpmG-ZmjZ"
      },
      "source": [
        "![texto alternativo](https://wikimedia.org/api/rest_v1/media/math/render/svg/c715ad94a83af2bbcc5eacc1ad48508e419dba96) Ecuación 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbFOsN4Ma4Bk"
      },
      "source": [
        "![texto alternativo](https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpartial+out_%7Bo1%7D%7D%7B%5Cpartial+net_%7Bo1%7D%7D+%3D+out_%7Bo1%7D%281+-+out_%7Bo1%7D%29+%3D+0.75136507%281+-+0.75136507%29+%3D+0.186815602&bg=ffffff&fg=404040&s=0&zoom=2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVFlJPX_YEpw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "784fadb2-aff5-40cd-847d-547e18fd3821"
      },
      "source": [
        "#por lo tanto:\n",
        "\n",
        "delta_o1_wr_net_o1=out_o1*(1-out_o1)\n",
        "print(delta_o1_wr_net_o1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.18681560180895948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXmhNIA_bD7Y"
      },
      "source": [
        "### 3.1.3 Componente 3: ¿cómo cambia el valor neto de la neurona o1 cuando cambia w5?\n",
        "### es simplemente el valor de la neurona h1\n",
        "![texto alternativo](https://s0.wp.com/latex.php?latex=net_%7Bo1%7D+%3D+w_5+%2A+out_%7Bh1%7D+%2B+w_6+%2A+out_%7Bh2%7D+%2B+b_2+%2A+1&bg=ffffff&fg=404040&s=0&zoom=2)\n",
        "\n",
        "![texto alternativo](https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpartial+net_%7Bo1%7D%7D%7B%5Cpartial+w_%7B5%7D%7D+%3D+1+%2A+out_%7Bh1%7D+%2A+w_5%5E%7B%281+-+1%29%7D+%2B+0+%2B+0+%3D+out_%7Bh1%7D+%3D+0.593269992&bg=ffffff&fg=404040&s=0&zoom=2) Ecuación 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-WEBpZNbDWz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9c5d396-d731-45de-dc0c-f30ee257ada2"
      },
      "source": [
        "#numericamente:\n",
        "\n",
        "delta_net_o1_wr_w5=out_h1\n",
        "print(delta_net_o1_wr_w5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5932699921071872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "283fszWscCTr"
      },
      "source": [
        "### 3.1.4 Finalmente puedo obtener el resultado de la pregunta original:\n",
        "###¿ Cúanto cambia el Error Total cuando cambia el parámetro w5?:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2w4mDekFcQgR"
      },
      "source": [
        "Recordando:\n",
        "![texto alternativo](https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpartial+E_%7Btotal%7D%7D%7B%5Cpartial+w_%7B5%7D%7D+%3D+%5Cfrac%7B%5Cpartial+E_%7Btotal%7D%7D%7B%5Cpartial+out_%7Bo1%7D%7D+%2A+%5Cfrac%7B%5Cpartial+out_%7Bo1%7D%7D%7B%5Cpartial+net_%7Bo1%7D%7D+%2A+%5Cfrac%7B%5Cpartial+net_%7Bo1%7D%7D%7B%5Cpartial+w_%7B5%7D%7D&bg=ffffff&fg=404040&s=2&zoom=2) Ecuación 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JibJgiyJcZwq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8c7dd8d-121a-42ea-c4dc-40e088c5c9c8"
      },
      "source": [
        "delta_e_total_wr_w5=delta_e_wr_delta_out_o1*delta_o1_wr_net_o1*delta_net_o1_wr_w5\n",
        "print(delta_e_total_wr_w5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.08216704056423078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZ72efFecqji",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54e99543-6803-4346-98c6-00bedc91018e"
      },
      "source": [
        "## o equivalentemente\n",
        "e1*out_o1*(1-out_o1)*out_h1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08216704056423077"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njW0j7EPc1_l"
      },
      "source": [
        "### Esta ecuación también se conoce como \"delta rule\":\n",
        "![texto alternativo](https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpartial+E_%7Btotal%7D%7D%7B%5Cpartial+w_%7B5%7D%7D+%3D+-%28target_%7Bo1%7D+-+out_%7Bo1%7D%29+%2A+out_%7Bo1%7D%281+-+out_%7Bo1%7D%29+%2A+out_%7Bh1%7D&bg=D5E9F6&fg=404040&s=0&zoom=2) Ecuación 7."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjQhFcyHdLY_"
      },
      "source": [
        "### Podemos replicar el proceso o ocupar la delta rule para obtener las derivadas de los parámetros faltantes, w6, w7, w8:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09RY-9bHdUo1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b01b118-c8a9-4d1f-84f9-df0bc5e97e65"
      },
      "source": [
        "delta_e_total_wr_w6=e1*out_o1*(1-out_o1)*out_h2\n",
        "delta_e_total_wr_w7=e2*out_o2*(1-out_o2)*out_h1\n",
        "delta_e_total_wr_w8=e2*out_o2*(1-out_o2)*out_h2\n",
        "\n",
        "print(delta_e_total_wr_w6,delta_e_total_wr_w7,delta_e_total_wr_w8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.08266762784753325 -0.02260254047747507 -0.022740242215978222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVJeHvCAfTwY"
      },
      "source": [
        "## 3.2 Actualizando los parámetros de la capa de salida usando los gradientes estimados.\n",
        "\n",
        "### Conociendo el gradiente (matriz de todas las derivadas parciales) ahora podemos calcular los nuevos pesos siguiendo la lógica del gradiente descendiente (me muevo en la dirección opuesta para minimizar el error).\n",
        "### por ejemplo para actualizar el parametro w5:\n",
        "![texto alternativo](https://s0.wp.com/latex.php?latex=w_5%5E%7B%2B%7D+%3D+w_5+-+%5Ceta+%2A+%5Cfrac%7B%5Cpartial+E_%7Btotal%7D%7D%7B%5Cpartial+w_%7B5%7D%7D+%3D+0.4+-+0.5+%2A+0.082167041+%3D+0.35891648&bg=ffffff&fg=404040&s=0&zoom=2) Ecuación 8.\n",
        "\n",
        "### n representa a la letra griega \"eta\" y se conoce como la tasa de aprendizaje o \"learning rate\", en este caso eta=0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "995fI6kjd7gf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d9d78fc-5d4f-4665-b9c2-6ab6ef0450ab"
      },
      "source": [
        "#numericamente\n",
        "eta=0.5\n",
        "w5_new=w5-eta*delta_e_total_wr_w5\n",
        "print(w5_new)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.35891647971788465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ntFIiSpgTno",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a39c0140-0188-4710-a0b8-3de3f881185e"
      },
      "source": [
        "#equivalentemente para los otros parámetros:\n",
        "w6_new=w6-eta*delta_e_total_wr_w6\n",
        "w7_new=w7-eta*delta_e_total_wr_w7\n",
        "w8_new=w8-eta*delta_e_total_wr_w8\n",
        "\n",
        "print(w6_new,w7_new,w8_new)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4086661860762334 0.5113012702387375 0.5613701211079891\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHbwXXIBk28i"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## 4. Siguiente paso: ¿Cómo actualizar los parámetros de la capa oculta?\n",
        "### Procedamos ahora a discutir como podemos estimar el efecto de los parámetros que están más \"escondidos\" en la red, es decir, aquellos que no se encuentran directamente conectados a las salidas.\n",
        "### Por ejemplo, ¿cómo podemos estimar cúanto afecta el parametro w1 al error total y así, poder optimizarlo en la próxima iteración?\n",
        "\n",
        "\n",
        "#### visualmente:\n",
        "![texto alternativo](https://drive.google.com/uc?id=1wlVYusuLRoSmZ-JEwZdjOfN4M532rVSo) Figura 4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj7iyEn3sYge"
      },
      "source": [
        "### Una vez más ocuparemos el truco del encadenamiento de efectos, o \"regla de la cadena\".\n",
        "### En la figura anterior podemos ver la cadena de eventos que nos interesa. El error Total depende de la salida de las neuronas o1 y o2. Éstas a su vez dependen del output de la neurona h1. Este ouput depende del valor antes de la activación, es decir, del valor neto. Finalmente, este valor neto depende de w1.\n",
        "\n",
        "### Matemáticamente podemos mostrar esta relación cómo:\n",
        "\n",
        "![texto alternativo](https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpartial+E_%7Btotal%7D%7D%7B%5Cpartial+w_%7B1%7D%7D+%3D+%5Cfrac%7B%5Cpartial+E_%7Btotal%7D%7D%7B%5Cpartial+out_%7Bh1%7D%7D+%2A+%5Cfrac%7B%5Cpartial+out_%7Bh1%7D%7D%7B%5Cpartial+net_%7Bh1%7D%7D+%2A+%5Cfrac%7B%5Cpartial+net_%7Bh1%7D%7D%7B%5Cpartial+w_%7B1%7D%7D&bg=ffffff&fg=404040&s=0&zoom=2) Ecuación 9.\n",
        "\n",
        "### La Ecuación 9 es clave para contestar nuestra pregunta, pero note que está compuesta por 3 componentes principales. Además, cada uno de estos componentes estará \"encadenado\" a los resultados de las capas posteriores, es decir, tendrá sub-componentes propios que tendremos que ir estimando cuidadosamente.\n",
        "\n",
        "\n",
        "### Así, el primer término de la Ecuación 9, puede a su vez ser descompuesto en 2 sub-componentes, las partes que corresponden a cada uno de los errores (Ecuación 10):\n",
        "\n",
        "![texto alternativo](https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpartial+E_%7Btotal%7D%7D%7B%5Cpartial+out_%7Bh1%7D%7D+%3D+%5Cfrac%7B%5Cpartial+E_%7Bo1%7D%7D%7B%5Cpartial+out_%7Bh1%7D%7D+%2B+%5Cfrac%7B%5Cpartial+E_%7Bo2%7D%7D%7B%5Cpartial+out_%7Bh1%7D%7D&bg=ffffff&fg=404040&s=0&zoom=2) Ecuación 10.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV9eTLcntV2S"
      },
      "source": [
        "### 4.1 Podemos estimar ahora el primer término:\n",
        "\n",
        "![texto alternativo](https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpartial+E_%7Bo1%7D%7D%7B%5Cpartial+out_%7Bh1%7D%7D+%3D+%5Cfrac%7B%5Cpartial+E_%7Bo1%7D%7D%7B%5Cpartial+net_%7Bo1%7D%7D+%2A+%5Cfrac%7B%5Cpartial+net_%7Bo1%7D%7D%7B%5Cpartial+out_%7Bh1%7D%7D&bg=ffffff&fg=404040&s=0&zoom=2) Ecuacion 11.\n",
        "\n",
        "### 4.1.1 Respecto del primer componente, ya conocemos su estructura y valores númericos:\n",
        "\n",
        "![texto alternativo](https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpartial+E_%7Bo1%7D%7D%7B%5Cpartial+out_%7Bh1%7D%7D&bg=ffffff&fg=404040&s=0&zoom=2) Ecuación 12.\n",
        "\n",
        "![texto alternativo](https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpartial+E_%7Bo1%7D%7D%7B%5Cpartial+net_%7Bo1%7D%7D+%3D+%5Cfrac%7B%5Cpartial+E_%7Bo1%7D%7D%7B%5Cpartial+out_%7Bo1%7D%7D+%2A+%5Cfrac%7B%5Cpartial+out_%7Bo1%7D%7D%7B%5Cpartial+net_%7Bo1%7D%7D+%3D+0.74136507+%2A+0.186815602+%3D+0.138498562&bg=ffffff&fg=404040&s=0&zoom=2) Ecuación 13"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcOPWZbBtq7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1741825-f24a-4be6-ac26-2f2ef34a2540"
      },
      "source": [
        "delta_e_o1_wr_delta_out_o1=-(o1-out_o1)\n",
        "print(delta_e_o1_wr_delta_out_o1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7413650695523157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdPl7Wyvt4Ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "252ba556-c7b0-4234-b146-0806cca2eea9"
      },
      "source": [
        "delta_o1_wr_net_o1=out_o1*(1-out_o1)\n",
        "print(delta_o1_wr_net_o1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.18681560180895948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRO-KYP51BV2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd396e3a-4538-428d-a356-6f7d17227062"
      },
      "source": [
        "# valor estimado:\n",
        "delta_eo1_wr_net_o1=delta_e_o1_wr_delta_out_o1*delta_o1_wr_net_o1\n",
        "print(delta_eo1_wr_net_o1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.13849856162855698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_GkK42d8JZy"
      },
      "source": [
        "### 4.1.2 Respecto del segundo componente:\n",
        "\n",
        "![texto alternativo](https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpartial+net_%7Bo1%7D%7D%7B%5Cpartial+out_%7Bh1%7D%7D&bg=ffffff&fg=404040&s=0&zoom=2) Ecuación 14.\n",
        "\n",
        "### Podemos estimar esta derivada cómo:\n",
        "\n",
        "![texto alternativo](https://s0.wp.com/latex.php?latex=net_%7Bo1%7D+%3D+w_5+%2A+out_%7Bh1%7D+%2B+w_6+%2A+out_%7Bh2%7D+%2B+b_2+%2A+1&bg=ffffff&fg=404040&s=0&zoom=2) Ecuación 15.\n",
        "\n",
        "### Lo que nos da como resultado simplemente w5:\n",
        "\n",
        "![texto alternativo](https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpartial+net_%7Bo1%7D%7D%7B%5Cpartial+out_%7Bh1%7D%7D+%3D+w_5+%3D+0.40&bg=ffffff&fg=404040&s=0&zoom=2) Ecuación 16.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PjbgjHB8JAw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d9b9c1b-e9eb-4114-d56d-921aa0bf9bb2"
      },
      "source": [
        "delta_net_o1_wr_out_h1=w5\n",
        "print(delta_net_o1_wr_out_h1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ub9m3r0D9F0h"
      },
      "source": [
        "### Como ya tenemos todos los componentes podemos estimar el primer término de la ecuación 10:\n",
        "\n",
        "![texto alternativo](https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpartial+E_%7Bo1%7D%7D%7B%5Cpartial+out_%7Bh1%7D%7D+%3D+%5Cfrac%7B%5Cpartial+E_%7Bo1%7D%7D%7B%5Cpartial+net_%7Bo1%7D%7D+%2A+%5Cfrac%7B%5Cpartial+net_%7Bo1%7D%7D%7B%5Cpartial+out_%7Bh1%7D%7D+%3D+0.138498562+%2A+0.40+%3D+0.055399425&bg=ffffff&fg=404040&s=0&zoom=2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDOPme4Q7208",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b9767e3-903a-4823-949a-6270829a575a"
      },
      "source": [
        "delta_e_o1_wr_out_h1=delta_eo1_wr_net_o1*delta_net_o1_wr_out_h1\n",
        "print(delta_e_o1_wr_out_h1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05539942465142279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iizbBMJT9mef"
      },
      "source": [
        "### 4.2 Podemos replicar ahora esta lógica para estimar el segundo término de la ecuación 10:\n",
        "\n",
        "![texto alternativo](https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpartial+E_%7Bo2%7D%7D%7B%5Cpartial+out_%7Bh1%7D%7D&bg=ffffff&fg=404040&s=0&zoom=2)\n",
        "\n",
        "![texto alternativo](https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpartial+E_%7Bo2%7D%7D%7B%5Cpartial+out_%7Bh1%7D%7D+%3D+-0.019049119&bg=ffffff&fg=404040&s=0&zoom=2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V97cvKugUAx1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2acb70af-6a5f-49d3-cece-bd0f35f5eabb"
      },
      "source": [
        "# Estimando el segundo componente de la ecuación 10:\n",
        "delta_e_o2_wr_delta_out_o2=-(o2-out_o2)\n",
        "print(\"delta_e_o2_wr_delta_out_o2\")\n",
        "print(delta_e_o2_wr_delta_out_o2)\n",
        "\n",
        "\n",
        "delta_o2_wr_net_o2=out_o2*(1-out_o2)\n",
        "print(\"delta_o2_wr_net_o2\")\n",
        "print(delta_o2_wr_net_o2)\n",
        "\n",
        "\n",
        "delta_eo2_wr_net_o2=delta_e_o2_wr_delta_out_o2*delta_o2_wr_net_o2\n",
        "print(\"delta_eo2_wr_net_o2\")\n",
        "\n",
        "print(delta_eo2_wr_net_o2)\n",
        "\n",
        "delta_net_o2_wr_out_h1=w7  # notar que en este caso la derivada nos da w7\n",
        "print(\"delta_net_o2_wr_out_h1\")\n",
        "\n",
        "print(delta_net_o2_wr_out_h1)\n",
        "\n",
        "delta_e_o2_wr_out_h1=delta_eo2_wr_net_o2*delta_net_o2_wr_out_h1\n",
        "print(\"delta_e_o2_wr_out_h1\")\n",
        "print(delta_e_o2_wr_out_h1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "delta_e_o2_wr_delta_out_o2\n",
            "-0.21707153467853746\n",
            "delta_o2_wr_net_o2\n",
            "0.17551005281727122\n",
            "delta_eo2_wr_net_o2\n",
            "-0.03809823651655623\n",
            "delta_net_o2_wr_out_h1\n",
            "0.5\n",
            "delta_e_o2_wr_out_h1\n",
            "-0.019049118258278114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNCulhUWd324"
      },
      "source": [
        "### El resultado de la ecuación 10 es:\n",
        "\n",
        "![texto alternativo](https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpartial+E_%7Btotal%7D%7D%7B%5Cpartial+out_%7Bh1%7D%7D+%3D+%5Cfrac%7B%5Cpartial+E_%7Bo1%7D%7D%7B%5Cpartial+out_%7Bh1%7D%7D+%2B+%5Cfrac%7B%5Cpartial+E_%7Bo2%7D%7D%7B%5Cpartial+out_%7Bh1%7D%7D+%3D+0.055399425+%2B+-0.019049119+%3D+0.036350306&bg=ffffff&fg=404040&s=0&zoom=2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na-LSlMWd-An",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8982f603-5795-4952-9035-dd45160538b6"
      },
      "source": [
        "# El resultado de la ecuación 10 es:\n",
        "\n",
        "delta_e_total_delta_out_h1=delta_e_o1_wr_out_h1+delta_e_o2_wr_out_h1\n",
        "print(\"delta_e_total_delta_out_h1\")\n",
        "print(delta_e_total_delta_out_h1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "delta_e_total_delta_out_h1\n",
            "0.03635030639314468\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQrLufp_g0nv"
      },
      "source": [
        "### 4.5 Cálculo final del gradiente.\n",
        "\n",
        "### Recordando, la ecuación 10, representa sólo el primer componente de la ecuación 9, la que finalmente nos dará el efecto total del parámetro w1 en el error total:\n",
        "\n",
        "\n",
        "![texto alternativo](https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpartial+E_%7Btotal%7D%7D%7B%5Cpartial+w_%7B1%7D%7D+%3D+%5Cfrac%7B%5Cpartial+E_%7Btotal%7D%7D%7B%5Cpartial+out_%7Bh1%7D%7D+%2A+%5Cfrac%7B%5Cpartial+out_%7Bh1%7D%7D%7B%5Cpartial+net_%7Bh1%7D%7D+%2A+%5Cfrac%7B%5Cpartial+net_%7Bh1%7D%7D%7B%5Cpartial+w_%7B1%7D%7D&bg=ffffff&fg=404040&s=0&zoom=2) Ecuación 9.\n",
        "\n",
        "### Ahora estimaremos los otros dos componentes de la Ecuacipón 9, siguiendo la lógica que ocupamos en la sección anterior:\n",
        "### Para el componente:\n",
        "\n",
        "![texto alternativo](https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpartial+out_%7Bh1%7D%7D%7B%5Cpartial+net_%7Bh1%7D%7D&bg=ffffff&fg=404040&s=0&zoom=2)\n",
        "\n",
        "### sabemos que\n",
        "\n",
        "![texto alternativo](https://s0.wp.com/latex.php?latex=out_%7Bh1%7D+%3D+%5Cfrac%7B1%7D%7B1%2Be%5E%7B-net_%7Bh1%7D%7D%7D&bg=ffffff&fg=404040&s=0&zoom=2)\n",
        "\n",
        "### y que su derivada respecto de la entrada neta es:\n",
        "\n",
        "![texto alternativo](https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpartial+out_%7Bh1%7D%7D%7B%5Cpartial+net_%7Bh1%7D%7D+%3D+out_%7Bh1%7D%281+-+out_%7Bh1%7D%29+%3D+0.59326999%281+-+0.59326999+%29+%3D+0.241300709&bg=ffffff&fg=404040&s=0&zoom=2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I2a2WVih01_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66611871-ca37-4148-fe91-38cb7efe0600"
      },
      "source": [
        "delta_out_h1_wr_delta_net_h1=out_h1*(1-out_h1)\n",
        "print(\"delta_out_h1_wr_delta_net_h1\")\n",
        "print(delta_out_h1_wr_delta_net_h1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "delta_out_h1_wr_delta_net_h1\n",
            "0.24130070857232525\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rmBR3fxiC_y"
      },
      "source": [
        "### Para el componente:\n",
        "![texto alternativo](https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpartial+net_%7Bh1%7D%7D%7B%5Cpartial+w%7D&bg=ffffff&fg=404040&s=0&zoom=2)\n",
        "\n",
        "### calculamos la derivada del valor con respecto al w correspondiente, en este caso w1:\n",
        "\n",
        "![texto alternativo](https://s0.wp.com/latex.php?latex=net_%7Bh1%7D+%3D+w_1+%2A+i_1+%2B+w_3+%2A+i_2+%2B+b_1+%2A+1&bg=ffffff&fg=404040&s=0&zoom=2)\n",
        "\n",
        "![texto alternativo](https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpartial+net_%7Bh1%7D%7D%7B%5Cpartial+w_1%7D+%3D+i_1+%3D+0.05&bg=ffffff&fg=404040&s=0&zoom=2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt57i7Byisob",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fde4f74-c2fb-484d-b29a-e1e414f9e530"
      },
      "source": [
        "delta_net_h1_wr_w1=i1\n",
        "print(\"delta_net_h1_wr_w1\")\n",
        "print(delta_net_h1_wr_w1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "delta_net_h1_wr_w1\n",
            "0.05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuR0fWOHi2e-"
      },
      "source": [
        "### Ahora ya contamos con todos los componentes de la Ecuación 9:\n",
        "\n",
        "![texto alternativo](https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpartial+E_%7Btotal%7D%7D%7B%5Cpartial+w_%7B1%7D%7D+%3D+%5Cfrac%7B%5Cpartial+E_%7Btotal%7D%7D%7B%5Cpartial+out_%7Bh1%7D%7D+%2A+%5Cfrac%7B%5Cpartial+out_%7Bh1%7D%7D%7B%5Cpartial+net_%7Bh1%7D%7D+%2A+%5Cfrac%7B%5Cpartial+net_%7Bh1%7D%7D%7B%5Cpartial+w_%7B1%7D%7D&bg=ffffff&fg=404040&s=0&zoom=2)\n",
        "\n",
        "![texto alternativo](https://s0.wp.com/latex.php?latex=%5Cfrac%7B%5Cpartial+E_%7Btotal%7D%7D%7B%5Cpartial+w_%7B1%7D%7D+%3D+0.036350306+%2A+0.241300709+%2A+0.05+%3D+0.000438568&bg=ffffff&fg=404040&s=0&zoom=2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYRE_0MgjE9w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab8c6f34-e996-4434-ca59-7f888f296881"
      },
      "source": [
        "delta_e_total_wr_delta_w1=delta_e_total_delta_out_h1*delta_out_h1_wr_delta_net_h1*delta_net_h1_wr_w1\n",
        "print(\"delta_e_total_wr_delta_w1\")\n",
        "print(delta_e_total_wr_delta_w1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "delta_e_total_wr_delta_w1\n",
            "0.00043856773447434685\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOsNs5qVfXmy"
      },
      "source": [
        "### 4.6 Actualizando los parámetros de la capa oculta\n",
        "#### Cómo ya hemos estimado la derivada del error total respecto de w1 (Ecuación 9), podemos ocupar este gradiente para actualizar el parámetro hacía uno que disminuya el error. El nuevo valor del parámetro w1 será:\n",
        "\n",
        "![texto alternativo](https://s0.wp.com/latex.php?latex=w_1%5E%7B%2B%7D+%3D+w_1+-+%5Ceta+%2A+%5Cfrac%7B%5Cpartial+E_%7Btotal%7D%7D%7B%5Cpartial+w_%7B1%7D%7D+%3D+0.15+-+0.5+%2A+0.000438568+%3D+0.149780716&bg=ffffff&fg=404040&s=0&zoom=2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFIe6dOWf5V1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cc3f149-59b0-4927-d874-e745fd047747"
      },
      "source": [
        "w1_new=w1-eta*delta_e_total_wr_delta_w1\n",
        "print(\"w1_new\")\n",
        "print(w1_new)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w1_new\n",
            "0.1497807161327628\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-zn5mwBjuOH"
      },
      "source": [
        "### Repetiendo este procedimiento para w2, w3, y w4 obtendriamos:\n",
        "\n",
        "![texto alternativo](https://s0.wp.com/latex.php?latex=w_2%5E%7B%2B%7D+%3D+0.19956143&bg=ffffff&fg=404040&s=0&zoom=2)\n",
        "\n",
        "![texto alternativo](https://s0.wp.com/latex.php?latex=w_3%5E%7B%2B%7D+%3D+0.24975114&bg=ffffff&fg=404040&s=0&zoom=2)\n",
        "\n",
        "![texto alternativo](https://s0.wp.com/latex.php?latex=w_4%5E%7B%2B%7D+%3D+0.29950229&bg=ffffff&fg=404040&s=0&zoom=2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDZSYBpMkcB2"
      },
      "source": [
        "## ** Ejercicio propuesto. Verifique que los nuevos valores de w2, w3, y w4 son los indicados en la celda anterior.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSxrwcFwkkIZ"
      },
      "source": [
        "## 5. Nueva iteración usando los parámetros actualizados.\n",
        "### Si ahora ocupamos los nuevos valores de los parámetros obtendremos:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_VZtZ6Ojtqh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86ec22dd-1c39-445c-db9a-85c394695753"
      },
      "source": [
        "# Propagando los datos hacia adelante ->\n",
        "\n",
        "# Calculamos los valores netos de la neuronas de la capa oculta (netos, es decir, antes de aplicarles la función de activación logística)\n",
        "# podemos ver que es solo una suma ponderada de los inputs a los que se les suma un término constante o \"bias\":\n",
        "\n",
        "w1=w1_new\n",
        "w2=0.19956143\n",
        "w3=0.24975114\n",
        "w4=0.29950229\n",
        "w5=w5_new\n",
        "w6=w6_new\n",
        "w7=w8_new\n",
        "\n",
        "net_h1=i1*w1+i2*w2+b1\n",
        "net_h2=i1*w3+i2*w4+b1\n",
        "\n",
        "print('net_h1='+ str(net_h1))\n",
        "print('net_h2='+str(net_h2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "net_h1=0.37744517880663814\n",
            "net_h2=0.392437786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6920h393AL3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e26c329-29c5-4176-ffd1-9b92a5563eaf"
      },
      "source": [
        "# necesitamos aplicar la función de activación logística (u otra).\n",
        "\n",
        "# ahora la aplico a cada una de las neuronas de la capa oculta\n",
        "\n",
        "out_h1=logistic_func(net_h1)\n",
        "out_h2=logistic_func(net_h2)\n",
        "\n",
        "print('out_h1='+ str(out_h1))\n",
        "print('out_h2='+ str(out_h2))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out_h1=0.5932567636467482\n",
            "out_h2=0.5968694086464008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUogfuCpnNMr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "998abb0f-18a8-4f83-b6be-9f8602fdae5c"
      },
      "source": [
        "# calculamos el valor neto ocupando los pesos respectivos. notar que el input de las neuronas de la capa de salida o1 y o2,\n",
        "#es el output de las neuronas de la capa oculta\n",
        "\n",
        "net_o1=out_h1*w5+out_h2*w6+b2\n",
        "net_o2=out_h1*w7+out_h2*w8+b2\n",
        "\n",
        "print('net_o1='+ str(net_o1))\n",
        "print('net_o2='+ str(net_o2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "net_o1=1.0568499739940174\n",
            "net_o2=1.2613147960120292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-z7tFkvIloNd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "155eb697-7619-4484-b719-96daedbfea37"
      },
      "source": [
        "# nuevamente, a estos valores netos le aplicamos la función de activación Ecuación 1.\n",
        "out_o1=logistic_func(net_o1)\n",
        "out_o2=logistic_func(net_o2)\n",
        "\n",
        "print('out_o1='+ str(out_o1))\n",
        "print('out_o2='+ str(out_o2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out_o1=0.7420881111887568\n",
            "out_o2=0.7792523595555513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtOXuv1KnWKo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5e81da6-70c8-4e28-d4b7-72d44c3066ce"
      },
      "source": [
        "# Calculamos los errores\n",
        "\n",
        "e1=out_o1-o1\n",
        "e2=out_o2-o2\n",
        "\n",
        "print(e1,e2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7320881111887568 -0.21074764044444871\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-tpjQ7ql2aj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "470e497a-7500-4ba3-c67f-a9c5b7e1e149"
      },
      "source": [
        "loss_e1=0.5*(e1**2)\n",
        "loss_e2=0.5*(e2**2)\n",
        "\n",
        "print(loss_e1,loss_e2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.26797650127196077 0.022207283976451317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSUAMPqyl3M1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "158e3642-2457-4ad3-f7b1-5f45e01d71d4"
      },
      "source": [
        "total_error=loss_e1+loss_e2\n",
        "print(total_error)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2901837852484121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByikiypWns9Y"
      },
      "source": [
        "## Podremos notar que el error total en esta iteración (dado el eta=0.5) disminuyó considerablemente desde el valor inicial 0.298371109, a un valor de 0.2901837852484121. Si repitieramos este proceso muchas veces, lograriamos disminuir el error consistentemente, en el algunos caso incluyo llegando a Error total=0.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inaXWnNut1P-"
      },
      "source": [
        "## Si la red contara con muchas más capas ocultas, se seguiría repitiendo esta lógica hasta lograr optimizar todos los parámetros de la misma. La misma lógica se puede extender para optimizar también los parámetros b1 y b2 (bias o constantes).\n"
      ]
    }
  ]
}